{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Imagenet implementation.ipynb","provenance":[{"file_id":"1vSgqqqiIHrOGabLxwD0Cr83BOaK1THjZ","timestamp":1579837449714}],"private_outputs":true,"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1EKwXmlxj0WY","colab_type":"text"},"source":["#How to get Images from ImageNet with Python in Google Colaboratory\n","\n","The first step to train a model for image recognition is finding images that belong to the desired class (or classes), and ImageNet is very useful for this because it currently has 14,197,122 images with 21841 synsets indexed. ImageNet aims to provide on average 1000 images to illustrate each one of their 100,000 synsets, the majority of the synsets are nouns (80.000+).\n","\n","For instance if the synset needed is pictures of ships it can be found by searching for ship on the imagenet website and the result will be the following page which has the wnid: n04194289"]},{"cell_type":"markdown","metadata":{"id":"Lz42zfTtkKKQ","colab_type":"text"},"source":["#Get the list of URLs for the images of the synset:\n","\n","Said list of URLs can be downloaded from the URL http://www.image-net.org/api/text/imagenet.synset.geturls?wnid= followed by the wnid so in the case of ships it would be â€œhttp://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n04194289\" this can be done with the Python library BeautifulSoup:"]},{"cell_type":"code","metadata":{"id":"Fm2HdBQgjkY7","colab_type":"code","colab":{}},"source":["#code part 1\n","from bs4 import BeautifulSoup\n","import numpy as np\n","import requests\n","import cv2\n","import PIL.Image\n","import urllib\n","\n","page = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n04194289\")#ship synset\n","print(page.content)\n","\n","# BeautifulSoup is an HTML parsing library\n","\n","soup = BeautifulSoup(page.content, 'html.parser')#puts the content of the website into the soup variable, each url on a different line\n","#print(soup)\n","#print(soup.prettify())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wrI-fU3HkRPs","colab_type":"code","colab":{}},"source":["#code part 1.1\n","bikes_page = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n02834778\")#bicycle synset\n","print(bikes_page.content)\n","\n","# BeautifulSoup is an HTML parsing library\n","from bs4 import BeautifulSoup\n","bikes_soup = BeautifulSoup(bikes_page.content, 'html.parser')#puts the content of the website into the soup variable, each url on a different line"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jvp44JU0kWzD","colab_type":"code","colab":{}},"source":["#code part 2\n","str_soup=str(soup)#convert soup to string so it can be split\n","type(str_soup)\n","split_urls=str_soup.split('\\r\\n')#split so each url is a different possition on a list\n","print(len(split_urls))#print the length of the list so you know how many urls you have\n","\n","#code part 2.2\n","bikes_str_soup=str(bikes_soup)#convert soup to string so it can be split\n","type(bikes_str_soup)\n","bikes_split_urls=bikes_str_soup.split('\\r\\n')#split so each url is a different possition on a list\n","print(len(bikes_split_urls))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a-8ZThdTkaK7","colab_type":"text"},"source":["#Make folders\n"]},{"cell_type":"markdown","metadata":{"id":"sXg_vOrmt_Mg","colab_type":"text"},"source":["![alt text](http://upscfever.com/datasets/flow_from_directory.jpeg)"]},{"cell_type":"code","metadata":{"id":"RvnNPUMdkciv","colab_type":"code","colab":{}},"source":["#code part 3\n","#check if all the images where stored on the files system\n","!mkdir /content/train #create the Train folder\n","!mkdir /content/train/ships #create the ships folder\n","!mkdir /content/train/bikes #create the bikes folder\n","!mkdir /content/validation\n","!mkdir /content/validation/ships #create the ships folder\n","!mkdir /content/validation/bikes #create the bikes folder\n","#!ls /content/train/ships #list the files inside ships\n","!mkdir /content/test/ \n","!mkdir /content/test/test #list the files inside test"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ws5t46y-kg6X","colab_type":"code","colab":{}},"source":["#code part 4\n","img_rows, img_cols = 32, 32 #number of rows and columns to convert the images to\n","input_shape = (img_rows, img_cols, 3)#format to store the images (rows, columns,channels) called channels last\n","\n","def url_to_image(url):\n","\t# download the image, convert it to a NumPy array, and then read\n","\t# it into OpenCV format\n","\tresp = urllib.request.urlopen(url)\n","\timage = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n","\timage = cv2.imdecode(image, cv2.IMREAD_COLOR)\n"," \n","\t# return the image\n","\treturn image\n","\n","n_of_training_images=150#the number of training images to use\n","for progress in range(n_of_training_images):#store all the images on a directory\n","    # Print out progress whenever progress is a multiple of 20 so we can follow the\n","    # (relatively slow) progress\n","    if(progress%20==0):\n","        print(progress)\n","    if not split_urls[progress] == None:\n","      try:\n","        I = url_to_image(split_urls[progress])\n","        if (len(I.shape))==3: #check if the image has width, length and channels\n","          save_path = '/content/train/ships/img'+str(progress)+'.jpg'#create a name of each image\n","          cv2.imwrite(save_path,I)\n","\n","      except:\n","        None\n","\n","#do the same for bikes:\n","for progress in range(n_of_training_images):#store all the images on a directory\n","    # Print out progress whenever progress is a multiple of 20 so we can follow the\n","    # (relatively slow) progress\n","    if(progress%20==0):\n","        print(progress)\n","    if not bikes_split_urls[progress] == None:\n","      try:\n","        I = url_to_image(bikes_split_urls[progress])\n","        if (len(I.shape))==3: #check if the image has width, length and channels\n","          save_path = '/content/train/bikes/img'+str(progress)+'.jpg'#create a name of each image\n","          cv2.imwrite(save_path,I)\n","\n","      except:\n","        None\n","        \n","        \n","#Validation data:\n","\n","for progress in range(50):#store all the images on a directory\n","    # Print out progress whenever progress is a multiple of 20 so we can follow the\n","    # (relatively slow) progress\n","    if(progress%20==0):\n","        print(progress)\n","    if not split_urls[progress] == None:\n","      try:\n","        I = url_to_image(split_urls[n_of_training_images+progress])#get images that are different from the ones used for training\n","        if (len(I.shape))==3: #check if the image has width, length and channels\n","          save_path = '/content/validation/ships/img'+str(progress)+'.jpg'#create a name of each image\n","          cv2.imwrite(save_path,I)\n","\n","      except:\n","        None\n","\n","#do the same for bikes:\n","for progress in range(50):#store all the images on a directory\n","    # Print out progress whenever progress is a multiple of 20 so we can follow the\n","    # (relatively slow) progress\n","    if(progress%20==0):\n","        print(progress)\n","    if not bikes_split_urls[progress] == None:\n","      try:\n","        I = url_to_image(bikes_split_urls[n_of_training_images+progress])#get images that are different from the ones used for training\n","        if (len(I.shape))==3: #check if the image has width, length and channels\n","          save_path = '/content/validation/bikes/img'+str(progress)+'.jpg'#create a name of each image\n","          cv2.imwrite(save_path,I)\n","\n","      except:\n","        None\n","        \n","print(\"\\nTRAIN:\\n\")          \n","print(\"\\nlist the files inside ships directory:\\n\")        \n","!ls /content/train/ships #list the files inside ships\n","print(\"\\nlist the files inside bikes directory:\\n\")\n","!ls /content/train/bikes #list the files inside bikes\n","print(\"\\nVALIDATION:\\n\")\n","print(\"\\nlist the files inside ships directory:\\n\")        \n","!ls /content/validation/ships #list the files inside ships\n","print(\"\\nlist the files inside bikes directory:\\n\")\n","!ls /content/validation/bikes #list the files inside bikes   "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pM40BlVhuqQF","colab_type":"code","colab":{}},"source":["for progress in range(50):#store all the images on a directory\n","    # Print out progress whenever progress is a multiple of 20 so we can follow the\n","    # (relatively slow) progress\n","    if(progress%20==0):\n","        print(progress)\n","    if not split_urls[progress] == None:\n","      try:\n","        I = url_to_image(split_urls[n_of_training_images+progress+50])#get images that are different from the ones used for training\n","        if (len(I.shape))==3: #check if the image has width, length and channels\n","          save_path = '/content/test/test/ships_'+str(progress)+'.jpg'#create a name of each image\n","          cv2.imwrite(save_path,I)\n","\n","      except:\n","        None\n","\n","#do the same for bikes:\n","for progress in range(50):#store all the images on a directory\n","    # Print out progress whenever progress is a multiple of 20 so we can follow the\n","    # (relatively slow) progress\n","    if(progress%20==0):\n","        print(progress)\n","    if not bikes_split_urls[progress] == None:\n","      try:\n","        I = url_to_image(bikes_split_urls[n_of_training_images+progress+50])#get images that are different from the ones used for training\n","        if (len(I.shape))==3: #check if the image has width, length and channels\n","          save_path = '/content/test/test/bikes_'+str(progress)+'.jpg'#create a name of each image\n","          cv2.imwrite(save_path,I)\n","\n","      except:\n","        None\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PSlNCKJMGq7a","colab_type":"code","colab":{}},"source":["# Path to the train folder\n","import os\n","import pandas as pd\n","\n","original_test = '/content/test/test'\n"," \n","filenames = os.listdir(original_test)\n","categories = []\n","for filename in filenames:\n","    category = filename.split('_')[0]\n","    if category == 'ships':\n","        categories.append('ships')\n","    else:\n","        categories.append('bikes')\n","\n","data = pd.DataFrame({'filename':filenames,'label':categories})\n","\n","data.to_csv(\"original.csv\",index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UDQRgQz_QQhF","colab_type":"text"},"source":["#Data augmentation"]},{"cell_type":"code","metadata":{"id":"2zEuli2HL8Pj","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.layers import Dropout, Flatten, Dense\n","from keras.optimizers import SGD\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(\n","        rescale=1./255,\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        horizontal_flip=True)\n","\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","\n","\n","train_generator = train_datagen.flow_from_directory(\n","    directory=r\"/content/train/\",\n","    target_size=(32, 32),\n","    color_mode=\"rgb\",\n","    batch_size=32,\n","    class_mode=\"categorical\",\n","    shuffle=True,\n","    seed=42\n",")\n","\n","valid_generator = test_datagen.flow_from_directory(\n","    directory=r\"/content/validation/\",\n","    target_size=(32, 32),\n","    color_mode=\"rgb\",\n","    batch_size=32,\n","    class_mode=\"categorical\",\n","    shuffle=True,\n","    seed=42\n",")\n","\n","test_generator = test_datagen.flow_from_directory(\n","    directory=\"/content/test/\",\n","    target_size=(32, 32),\n","    color_mode=\"rgb\",\n","    batch_size=1,\n","    class_mode=None,\n","    shuffle=False,\n","    seed=42\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YD-cSPUPM8Hy","colab_type":"text"},"source":["#Fit the model"]},{"cell_type":"code","metadata":{"id":"Ypt-5dZnM7hT","colab_type":"code","colab":{}},"source":["from keras.utils.np_utils import to_categorical\n","from keras import models\n","from keras.datasets import cifar10\n","from keras.layers import Dense, Dropout\n","from keras.models import Sequential\n","from keras.layers import Activation, Flatten, Conv2D\n","from keras.utils import to_categorical\n","from keras.datasets import mnist\n","from keras.utils.vis_utils import model_to_dot\n","from IPython.display import SVG\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n","STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n","\n","\n","\n","model = Sequential()\n","#We need to use a Conv2D layer at start of the neural network \n","#the syntax is Conv2D(1, (image_width,image_height), padding=\"valid\", activation=\"relu\", input_shape=X_train.shape[1:])\n","#the we add a flatten layer\n","model.add(Conv2D(512, (32, 32), padding=\"valid\", activation=\"relu\", input_shape=(32, 32, 3)))\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dense(2))\n","model.add(Activation('softmax'))\n","\n","model.compile(loss='categorical_crossentropy',\n","                  optimizer='adam',\n","                  metrics=['accuracy'])\n","\n","\n","model.fit_generator(generator=train_generator,\n","                    steps_per_epoch=STEP_SIZE_TRAIN,\n","                    validation_data=valid_generator,\n","                    validation_steps=STEP_SIZE_VALID,\n","                    epochs=10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wxslFZBwNQEo","colab_type":"text"},"source":["#Evaluate the model"]},{"cell_type":"code","metadata":{"id":"URNPeVz1NRJB","colab_type":"code","colab":{}},"source":["model.evaluate_generator(generator=valid_generator, steps=STEP_SIZE_VALID)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"crqtzRl9X2lZ","colab_type":"text"},"source":["#Measure the performance on validation set"]},{"cell_type":"code","metadata":{"id":"AfKjajYHX5Q2","colab_type":"code","colab":{}},"source":["from sklearn.metrics import roc_auc_score\n","\n","# AUC for prediction on validation sample\n","X_val_sample, val_labels = next(valid_generator)\n","val_pred = model.predict_proba(X_val_sample)\n","val_pred = np.reshape(val_pred, val_labels.shape)\n","val_score_auc = roc_auc_score(val_labels, val_pred)\n","print (\"AUC validation score\")\n","print (val_score_auc)\n","print ('\\n')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yqoCLUOfNkom","colab_type":"text"},"source":["#Predict the output"]},{"cell_type":"code","metadata":{"id":"1Fxju6FFNmb1","colab_type":"code","colab":{}},"source":["import pandas as pd\n","\n","STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n","test_generator.reset()\n","pred=model.predict_generator(test_generator,\n","steps=STEP_SIZE_TEST,\n","verbose=1)\n","\n","predicted_class_indices=np.argmax(pred,axis=1)\n","\n","labels = (train_generator.class_indices)\n","labels = dict((v,k) for k,v in labels.items())\n","predictions = [labels[k] for k in predicted_class_indices]\n","\n","filenames=test_generator.filenames\n","results=pd.DataFrame({\"Filename\":filenames,\n","                      \"Predictions\":predictions})\n","results.to_csv(\"results.csv\",index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4LtZJ6sPGzQM","colab_type":"text"},"source":["#Data augmentation - Flow from dataframe"]},{"cell_type":"code","metadata":{"id":"oP2R9Ou5G5cf","colab_type":"code","colab":{}},"source":["#code part 1\n","from bs4 import BeautifulSoup\n","import numpy as np\n","import requests\n","import cv2\n","import PIL.Image\n","import urllib\n","\n","cats_page = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n02123159\")#cat synset\n","print(cats_page.content)\n","cats_soup = BeautifulSoup(cats_page.content, 'html.parser')#puts the content of the website into the soup variable, each url on a different line\n","dogs_page = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n02084071\")#dogs synset\n","print(dogs_page.content)\n","\n","from bs4 import BeautifulSoup\n","dogs_soup = BeautifulSoup(dogs_page.content, 'html.parser')#puts the content of the website into the soup variable, each url on a different line\n","\n","\n","#code part 2\n","cats_str_soup=str(cats_soup)#convert soup to string so it can be split\n","type(cats_str_soup)\n","cats_split_urls=cats_str_soup.split('\\r\\n')#split so each url is a different possition on a list\n","print(len(cats_split_urls))#print the length of the list so you know how many urls you have\n","\n","#code part 2.2\n","dogs_str_soup=str(dogs_soup)#convert soup to string so it can be split\n","type(dogs_str_soup)\n","dogs_split_urls=dogs_str_soup.split('\\r\\n')#split so each url is a different possition on a list\n","print(len(dogs_split_urls))\n","\n","\n","!mkdir /content/catsdogs_train/ \n","!mkdir /content/catsdogs_test/ \n","\n","img_rows, img_cols = 32, 32 #number of rows and columns to convert the images to\n","input_shape = (img_rows, img_cols, 3)#format to store the images (rows, columns,channels) called channels last\n","\n","def url_to_image(url):\n","\t# download the image, convert it to a NumPy array, and then read\n","\t# it into OpenCV format\n","\tresp = urllib.request.urlopen(url)\n","\timage = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n","\timage = cv2.imdecode(image, cv2.IMREAD_COLOR)\n"," \n","\t# return the image\n","\treturn image\n","\n","n_of_training_images=150#the number of training images to use\n","for progress in range(n_of_training_images):#store all the images on a directory\n"," \n","    if(progress%20==0):\n","        print(progress)\n","    if not cats_split_urls[progress] == None:\n","      try:\n","        I = url_to_image(cats_split_urls[progress])\n","        if (len(I.shape))==3: #check if the image has width, length and channels\n","          save_path = '/content/catsdogs_train/cats.'+str(progress)+'.jpg'#create a name of each image\n","          cv2.imwrite(save_path,I)\n","\n","      except:\n","        None\n","\n","for progress in range(n_of_training_images):#store all the images on a directory\n","  \n","    if(progress%20==0):\n","        print(progress)\n","    if not dogs_split_urls[progress] == None:\n","      try:\n","        I = url_to_image(dogs_split_urls[progress])\n","        if (len(I.shape))==3: #check if the image has width, length and channels\n","          save_path = '/content/catsdogs_train/dogs.'+str(progress)+'.jpg'#create a name of each image\n","          cv2.imwrite(save_path,I)\n","\n","      except:\n","        None"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_D6S7Ma5l0QL","colab_type":"text"},"source":["#Test data images"]},{"cell_type":"code","metadata":{"id":"B7DHRnzLl2JE","colab_type":"code","colab":{}},"source":["#Validation data:\n","\n","for progress in range(50):#store all the images on a directory\n","    # Print out progress whenever progress is a multiple of 20 so we can follow the\n","    # (relatively slow) progress\n","    if(progress%20==0):\n","        print(progress)\n","    if not split_urls[progress] == None:\n","      try:\n","        I = url_to_image(split_urls[n_of_training_images+progress])#get images that are different from the ones used for training\n","        if (len(I.shape))==3: #check if the image has width, length and channels\n","          save_path = '/content/catsdogs_test/cats.'+str(progress)+'.jpg'#create a name of each image\n","          cv2.imwrite(save_path,I)\n","\n","      except:\n","        None\n","\n","#do the same for bikes:\n","for progress in range(50):#store all the images on a directory\n","    # Print out progress whenever progress is a multiple of 20 so we can follow the\n","    # (relatively slow) progress\n","    if(progress%20==0):\n","        print(progress)\n","    if not bikes_split_urls[progress] == None:\n","      try:\n","        I = url_to_image(bikes_split_urls[n_of_training_images+progress])#get images that are different from the ones used for training\n","        if (len(I.shape))==3: #check if the image has width, length and channels\n","          save_path = '/content/catsdogs_test/dogs.'+str(progress)+'.jpg'#create a name of each image\n","          cv2.imwrite(save_path,I)\n","\n","      except:\n","        None"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yy4gvz0UktHZ","colab_type":"text"},"source":["#Save images to folder"]},{"cell_type":"code","metadata":{"id":"q_xEzEEsG90r","colab_type":"code","colab":{}},"source":["# Path to the train folder\n","import os\n","original_train = '/content/catsdogs_train/'\n"," \n","filenames = os.listdir(original_train)\n","categories = []\n","for filename in filenames:\n","    category = filename.split('.')[0]\n","    if category == 'cats':\n","        categories.append('0')\n","    else:\n","        categories.append('1')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jt2YSDOskwuE","colab_type":"text"},"source":["#Create dataframe from folder"]},{"cell_type":"code","metadata":{"id":"QALGG9VZHAos","colab_type":"code","colab":{}},"source":["import pandas as pd\n","data = pd.DataFrame({'filename':filenames,'label':categories})\n","\n","data.to_csv(\"original_catsdogs.csv\",index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bM8CbzlXk0Ms","colab_type":"text"},"source":["#Split dataframe into train and test"]},{"cell_type":"code","metadata":{"id":"qTxcAxQejUM1","colab_type":"code","colab":{}},"source":["msk = np.random.rand(len(data)) < 0.8\n","\n","train = data[msk]\n","\n","test = data[~msk]\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bk-iwznOHtn6","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.layers import Dropout, Flatten, Dense\n","from keras.optimizers import SGD\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","datagen = ImageDataGenerator(\n","        rescale=1./255,\n","        shear_range=0.2,\n","        zoom_range=0.2,\n","        horizontal_flip=True,\n","        validation_split=0.2)\n","\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","\n","\n","train_generator = datagen.flow_from_dataframe(dataframe=train, directory=original_train,\n","                                             x_col='filename',\n","                                             y_col='label',\n","                                             target_size=(150,150),\n","                                             class_mode='binary',\n","                                             batch_size=10,\n","                                             subset='training',\n","                                             shuffle=True,\n","                                             seed=7)\n"," \n","validation_generator = datagen.flow_from_dataframe(dataframe=train, directory=original_train,\n","                                             x_col='filename',\n","                                             y_col='label',\n","                                             target_size=(150,150),\n","                                             class_mode='binary',\n","                                             batch_size=10,\n","                                             subset='validation',\n","                                             shuffle=True,\n","                                             seed=7)\n","\n","test_datagen=ImageDataGenerator(rescale=1./255.)\n","\n","test_generator=test_datagen.flow_from_dataframe(\n","dataframe=test,\n","directory=\"/content/catsdogs_test/\",\n","x_col=\"id\",\n","y_col=None,\n","batch_size=32,\n","seed=42,\n","shuffle=False,\n","class_mode=None,\n","target_size=(150,150))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Taw_PmJbminf","colab_type":"text"},"source":["#Model building"]},{"cell_type":"code","metadata":{"id":"twev8tYZmkX1","colab_type":"code","colab":{}},"source":["from keras.utils.np_utils import to_categorical\n","from keras import models\n","from keras.datasets import cifar10\n","from keras.layers import Dense, Dropout\n","from keras.models import Sequential\n","from keras.layers import Activation, Flatten, Conv2D\n","from keras.utils import to_categorical\n","from keras.datasets import mnist\n","from keras.utils.vis_utils import model_to_dot\n","from IPython.display import SVG\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n","STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n","STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n","\n","\n","\n","model = Sequential()\n","#We need to use a Conv2D layer at start of the neural network \n","#the syntax is Conv2D(1, (image_width,image_height), padding=\"valid\", activation=\"relu\", input_shape=X_train.shape[1:])\n","#the we add a flatten layer\n","model.add(Conv2D(512, (150, 150), padding=\"valid\", activation=\"relu\", input_shape=(150, 150, 3)))\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dense(2))\n","model.add(Activation('softmax'))\n","\n","model.compile(loss='categorical_crossentropy',\n","                  optimizer='adam',\n","                  metrics=['accuracy'])\n","\n","\n","model.fit_generator(generator=train_generator,\n","                    steps_per_epoch=STEP_SIZE_TRAIN,\n","                    validation_data=valid_generator,\n","                    validation_steps=STEP_SIZE_VALID,\n","                    epochs=10)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RdJaUvqVm0tn","colab_type":"text"},"source":["#Evaluate the model"]},{"cell_type":"code","metadata":{"id":"DnVOz-K5m17H","colab_type":"code","colab":{}},"source":["model.evaluate_generator(generator=valid_generator,steps=STEP_SIZE_TEST)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E0B7s-NSnKg_","colab_type":"text"},"source":["#Measure the performance on validation set"]},{"cell_type":"code","metadata":{"id":"xJsMJIb2nLS0","colab_type":"code","colab":{}},"source":["from sklearn.metrics import roc_auc_score\n","\n","# AUC for prediction on validation sample\n","X_val_sample, val_labels = next(valid_generator)\n","val_pred = model.predict_proba(X_val_sample)\n","val_pred = np.reshape(val_pred, val_labels.shape)\n","val_score_auc = roc_auc_score(val_labels, val_pred)\n","print (\"AUC validation score\")\n","print (val_score_auc)\n","print ('\\n')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FAU7xrc6m5gn","colab_type":"text"},"source":["#Predict the output"]},{"cell_type":"code","metadata":{"id":"DfUjO9mam6jY","colab_type":"code","colab":{}},"source":["test_generator.reset()\n","pred=model.predict_generator(test_generator,\n","steps=STEP_SIZE_TEST,\n","verbose=1)\n","\n","predicted_class_indices=np.argmax(pred,axis=1)\n","\n","labels = (train_generator.class_indices)\n","labels = dict((v,k) for k,v in labels.items())\n","predictions = [labels[k] for k in predicted_class_indices]\n","\n","#Finally, save the results to a CSV file.\n","\n","filenames=test_generator.filenames\n","results=pd.DataFrame({\"Filename\":filenames,\n","                      \"Predictions\":predictions})\n","results.to_csv(\"results.csv\",index=False)"],"execution_count":0,"outputs":[]}]}